<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Camera Input Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <style>
    #video {
      display: none;
    }
  </style>
</head>
<body>
  <video id="video"></video>
  <canvas id="cvs"></canvas>
  <script>
    let model = null;
    async function init() {
      // Load the model.
      model = await blazeface.load();
    }
    init();
    const ctx = document.querySelector("#cvs").getContext("2d");
    const video = document.querySelector("#video");
    window.navigator.mediaDevices.getUserMedia({
      audio: false,
      video: true
    }).then((stream)=>{
      video.srcObject = stream;
      video.play();
    })
    
    async function refresh() {
    
   
    // Pass in an image or video to the model. The model returns an array of
    // bounding boxes, probabilities, and landmarks, one for each detected face.

    const returnTensors = false; // Pass in `true` to get tensors back, rather than values.
    const predictions = await model.estimateFaces(video, returnTensors);
    ctx.canvas.width = video.videoWidth;
    ctx.canvas.height = video.videoHeight;
    if (predictions.length > 0) {
      /*
      `predictions` is an array of objects describing each detected face, for example:

      [
        {
          topLeft: [232.28, 145.26],
          bottomRight: [449.75, 308.36],
          probability: [0.998],
          landmarks: [
            [295.13, 177.64], // right eye
            [382.32, 175.56], // left eye
            [341.18, 205.03], // nose
            [345.12, 250.61], // mouth
            [252.76, 211.37], // right ear
            [431.20, 204.93] // left ear
          ]
        }
      ]
      */

      for (let i = 0; i < predictions.length; i++) {
        const rightEye = predictions[i].landmarks[0];
        const leftEye = predictions[i].landmarks[1];
        const start = predictions[i].topLeft;
        const end = predictions[i].bottomRight;
        const size = [end[0] - start[0], end[1] - start[1]];

        // Render original image
        const faceArea = new Path2D();
        // faceArea.rect(start[0], start[1], size[0], size[1])
        faceArea.ellipse((leftEye[0]+rightEye[0])/2, (leftEye[1]+rightEye[1])/2, size[0]*0.5, size[0]*0.875, 0, 0, 2*Math.PI)
        ctx.save();
        ctx.clip(faceArea);
        ctx.drawImage(video, 0, 0);
        ctx.restore();
      }
    }

    ctx.save();
    ctx.filter="blur(10px)";
    ctx.globalCompositeOperation="destination-atop";
    ctx.drawImage(video, 0, 0);
    ctx.restore();
  }
  window.setInterval(refresh, 100);
  </script>
</body>
</html>