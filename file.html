<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Camera Detect</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
</head>
<body>
  <div>
    choose <input type="file" onchange="loadFile(this)"/>
  </div>
  <canvas id="cvs"></canvas>
<script>
  const ctx = document.querySelector("#cvs").getContext("2d");
  let model = null;
  async function init() {
    // Load the model.
    model = await blazeface.load();
  }
  init();
  function loadFile(input) {
    const file = input.files[0];
    // console.log(file);
    const img = new Image();
    img.src = URL.createObjectURL(file);
    img.addEventListener("load", ()=>{
      ctx.canvas.width = img.width;
      ctx.canvas.height = img.height;
      // ctx.drawImage(img,0 ,0);
      detect(img);
    })
  }
  async function detect(img) {
    

    // Pass in an image or video to the model. The model returns an array of
    // bounding boxes, probabilities, and landmarks, one for each detected face.

    const returnTensors = false; // Pass in `true` to get tensors back, rather than values.
    const predictions = await model.estimateFaces(img, returnTensors);

    if (predictions.length > 0) {
      /*
      `predictions` is an array of objects describing each detected face, for example:

      [
        {
          topLeft: [232.28, 145.26],
          bottomRight: [449.75, 308.36],
          probability: [0.998],
          landmarks: [
            [295.13, 177.64], // right eye
            [382.32, 175.56], // left eye
            [341.18, 205.03], // nose
            [345.12, 250.61], // mouth
            [252.76, 211.37], // right ear
            [431.20, 204.93] // left ear
          ]
        }
      ]
      */

      for (let i = 0; i < predictions.length; i++) {
        const rightEye = predictions[i].landmarks[0];
        const leftEye = predictions[i].landmarks[1];
        const start = predictions[i].topLeft;
        const end = predictions[i].bottomRight;
        const size = [end[0] - start[0], end[1] - start[1]];

        // Render original image
        const faceArea = new Path2D();
        // faceArea.rect(start[0], start[1], size[0], size[1])
        faceArea.ellipse((leftEye[0]+rightEye[0])/2, (leftEye[1]+rightEye[1])/2, size[0]*0.5, size[0]*0.875, 0, 0, 2*Math.PI)
        ctx.save();
        ctx.clip(faceArea);
        ctx.drawImage(img, 0, 0);
        ctx.restore();
      }
    }

    ctx.save();
    ctx.filter="blur(10px)";
    ctx.globalCompositeOperation="destination-atop";
    ctx.drawImage(img, 0, 0);
    ctx.restore();
  }

  // main();
</script>
</body>
</html>